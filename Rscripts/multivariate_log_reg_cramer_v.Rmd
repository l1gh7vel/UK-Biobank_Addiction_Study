---
title: "january_7_log_reg"
output: pdf_document
date: "2024-01-07"
---

This file has code to do multivariate logistic regressions with cramer's V multicollinearity removal for the SNPs selected after lasso and SNP-SNP interactions found in SNPAssoc for each of the groups (male, female, overall in main and sub studies)
 

STEP 1: Install the following packages using install.packages() function and load them using library() function.

```{r}
library(mlbench)     # For PimaIndiansDiabetes2 dataset
library(dplyr)       # For data manipulation (dplyr) 
library(broom)       # For making model summary tidy
library(visreg)      # For plotting logodds and probability 
library(rcompanion)  # To calculate pseudo R-squared
library(MASS)        # For stepwise model selection
library(ROCR)        # To find the probability threshold for best accuracy
library(car)         # For multicollinearity function vif()
```

STEP 2: Load the data set

```{r}
currData = read.csv("../data/male_cutoff_1_data.csv")
head(currData)
str(currData)

```

Our next task is to process the data so that it gets compatible with the R functions.

STEP 3. Data Preparation

1: Remove data rows with NA values using na.omit() function (will try without this for now).
2: Convert the dependent variable "ADD_binary" into integer values (neg:0 and pos:1) using levels() function.
2.5: Remove unneeded columns (ID_1, X)
3: Check the refined version of the data using str() function.

```{r}

attach(currData)
levels(currData$ADD_binary) = 0:1          # Setting the dependent variable to 0 and 1.

# Columns to keep as-is
columns_to_keep_as_is <- c("Age_n", "TSDI_n")

# Convert all other columns to factors
currData[, setdiff(names(currData), columns_to_keep_as_is)] <- lapply(
  currData[, setdiff(names(currData), columns_to_keep_as_is)],
  as.factor
)

currData_new <- subset(currData, select = -c(ID_1, X))
str(currData_new)                            # Checking the structure of the data frame.
```

Changed all variables to factor type except AGE_n and TSDI_n, which are normalized numerical types


III.B. MODEL FITTING (BINARY LOGISTIC REGRESSION)

STEP 1. FITTING A MODEL TO STUDY THE IMPORTANCE OF VARIABLES: 

In order to fit a logistic regression model, you need to use the glm() function and inside that, you have to provide the formula, training data and family = "binomial".

i.  Plus notation:      diabetes ~ ind_variable_1 + ind_variable_2 + â€¦ so on
ii. Tilde dot notation: diabetes ~ .  means diabetes is predicted by the rest of the variables in the data frame except the dependent variable i.e. diabetes.

```{r}
# WE USE THE ENTIRE DATASET HERE
model_logi = glm(ADD_binary~., data=currData_new, family = "binomial")      # Fitting a binary logistic regression
summary(model_logi)                                                   # Model summary
```



STEP 3. Model Interpretation 



After model fitting, the next step is to generate the model summary table and interpret the model coefficients. The coefficients are in log-odds terms. 


ODDS Ratio: The interpretation of coefficients in the log-odds term is hard. But, we can compute the odds ratio by taking exponent of the estimated coefficients, and report it. 

```{r}

odds_ratio_table = tidy(model_logi, exponentiate = TRUE, conf.level = 0.95) # without conf. interval

odds_ratio_table
```


Remove the "1" at the end of each variable name that stupid R puts for creating dummies of categorical vars. BEWARE that if you do not put the snps as factors, this should not be done. ALSO MAKE SURE ANY OF THE NON-CATEGORICAL VARIABLES SHOULDN'T END IN 1
```{r}
odds_ratio_table$term <- sub("1$", "", odds_ratio_table$term)

odds_ratio_table
```



checking using cramer's v
```{r}
library(confintr)
removeVariablesBasedOnCramersV <- function(data, odds_ratio_table, threshold, non_categorical_vars) {
  # Function to adjust odds ratio
  adjust_odds_ratio <- function(odds_ratio) {
    SIGMA = 0.001
    if (is.na(odds_ratio)) {
      return(NA)  # Return NA if input is NA
    } else if (odds_ratio < 1) {
      return(1 / (odds_ratio + SIGMA))
    } else {
      return(odds_ratio)
    }
  }
  
  # Exclude non-categorical variables
  categorical_variables <- setdiff(names(data), non_categorical_vars)
  variables_to_remove <- vector()

  # Identify pairs and decide which variable to remove
  for (i in 1:(length(categorical_variables) - 1)) {
    for (j in (i + 1):length(categorical_variables)) {
      contingency_table <- table(data[[categorical_variables[i]]], data[[categorical_variables[j]]])
      cramers_v_result <- cramersv(contingency_table)

      if (cramers_v_result > threshold) {
        cat("Cramer's V between", categorical_variables[i], "and", categorical_variables[j], ":", cramers_v_result, "\n")
        # Get odds ratios for the variables
        odds_ratio_i <- odds_ratio_table[odds_ratio_table$term == categorical_variables[i], "estimate"]
        odds_ratio_j <- odds_ratio_table[odds_ratio_table$term == categorical_variables[j], "estimate"]

        # Check for NA before comparing
        if (!is.na(odds_ratio_i) & !is.na(odds_ratio_j)) {
          adjusted_odds_ratio_i <- adjust_odds_ratio(odds_ratio_i)
          adjusted_odds_ratio_j <- adjust_odds_ratio(odds_ratio_j)

          # Compare odds ratios and select variable for removal
          if (adjusted_odds_ratio_i > adjusted_odds_ratio_j) {
            variable_to_remove <- categorical_variables[j]
          } else {
            variable_to_remove <- categorical_variables[i]
          }

          # Add to the list if not already there
          if (!variable_to_remove %in% variables_to_remove) {
            variables_to_remove <- c(variables_to_remove, variable_to_remove)
          }
        }
      }
    }
  }
  
  # Remove identified variables from the data
  r_data <- data[ , !(names(data) %in% variables_to_remove)]
  return(r_data)
}

#haven't checked if the following line works yet
suppressWarnings({
  currData_new_2 = removeVariablesBasedOnCramersV(currData_new, odds_ratio_table, threshold = 0.8, c("Age_n", "TSDI_n"))

})


```

Re-running log reg for the data with fewer variables

```{r}

model_logi_2 = glm(ADD_binary~., data=currData_new_2, family = "binomial")      # Fitting a binary logistic regression
summary(model_logi_2)                                                   # Model summary
```

```{r}
odds_ratio_table_2 = tidy(model_logi_2, exponentiate = TRUE, conf.level = 0.95)
odds_ratio_table_2
odds_ratio_table_2$term <- sub("1$", "", odds_ratio_table_2$term)

odds_ratio_table_2
```


Removing again with cramer's v
```{r}
suppressWarnings({
  currData_new_3 = removeVariablesBasedOnCramersV(currData_new_2, odds_ratio_table_2, threshold = 0.8, c("Age_n", "TSDI_n"))
})




```

3rd re-run of log reg for the data with fewer variables

```{r}

model_logi_3 = glm(ADD_binary~., data=currData_new_3, family = "binomial")      # Fitting a binary logistic regression
summary(model_logi_3)                                                   # Model summary
```
Since the model finally ran without any singularity issues, let's check gvif:

Checking for multicollinearity (using gvif)

```{r}
library(glmtoolbox)
# Run GVIF and store the output
gvif_output <- gvif(model_logi_3)

# Extract the adjusted GVIF scores (third column)
gvif_scores <- gvif_output[, "GVIF^(1/(2*df))"]

# Set your cutoff value
cutoff <- 5

# Find variables that exceed the cutoff
variables_to_remove <- rownames(gvif_output)[gvif_scores > cutoff]

# Output the variables to remove
print(variables_to_remove)

currData_new_final = currData_new_3[ , !(names(currData_new_3) %in% variables_to_remove)]
```


Running the final model

```{r}

model_logi_final = glm(ADD_binary~., data=currData_new_final, family = "binomial")      # Fitting a binary logistic regression
summary(model_logi_final)    
```


reviewing the final summary of the model (odds ratio table)
have to change the name of the model etc. according to the one currently being used

```{r}
library(broom)

# the odds_ratio_table is created as follows
odds_ratio_table_final = tidy(model_logi_final, exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95)


# Rename the 'estimate' column to 'odds_ratio'
colnames(odds_ratio_table_final)[colnames(odds_ratio_table_final) == "estimate"] <- "odds_ratio"

# Extract p-values
original_p_values = odds_ratio_table_final$p.value

# Adjust p-values using Benjamini-Hochberg method
adjusted_p_values = p.adjust(original_p_values, method = "BH")

# Add adjusted p-values to the table
odds_ratio_table_final$adjusted_p_value = adjusted_p_values

# Now odds_ratio_table has an additional column with adjusted p-values

odds_ratio_table_final

odds_ratio_table_final$term <- sub("1$", "", odds_ratio_table_final$term)

```




```{r}
# Specify the file path where you want to save the CSV file
output_file <- "../results/male_cutoff_1_mvlog.csv"

# Export the odds ratio table to a CSV file
write.csv(odds_ratio_table_final, file = output_file, row.names = FALSE)
```
